{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom numpy.random import randint, randn, shuffle\nfrom numpy import expand_dims, zeros, ones, vstack\nimport numpy as np\nfrom matplotlib import pyplot\n%matplotlib inline\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Conv2DTranspose, Dropout, Flatten, LeakyReLU, Flatten, Reshape, Dense\nfrom keras.optimizers import Adam","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-11T10:23:54.392178Z","iopub.execute_input":"2021-07-11T10:23:54.39268Z","iopub.status.idle":"2021-07-11T10:23:54.408274Z","shell.execute_reply.started":"2021-07-11T10:23:54.392634Z","shell.execute_reply":"2021-07-11T10:23:54.407277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discriminator(input_shape=(28,28,1)):\n    model = Sequential()\n        \n    model.add(Conv2D(128, kernel_size=(2,2), strides=(2,2), input_shape=input_shape, padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.3))\n        \n    model.add(Conv2D(64, kernel_size=(3,3), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.3))\n        \n    model.add(Conv2D(32, kernel_size=(5,5), strides=(1,1),padding='same'))\n    model.add(Dropout(0.4))\n    model.add(Flatten())\n        \n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(16, activation='relu'))\n    model.add(Dense(1, activation='relu'))\n        \n    model.compile(optimizer='Adam', loss='binary_crossentropy',  metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:23:54.409967Z","iopub.execute_input":"2021-07-11T10:23:54.410343Z","iopub.status.idle":"2021-07-11T10:23:54.418944Z","shell.execute_reply.started":"2021-07-11T10:23:54.410305Z","shell.execute_reply":"2021-07-11T10:23:54.417655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generator(latent_dim):\n    model = Sequential()\n        \n    n_nodes = 128*7*7\n    # start with 7x7 image\n    model.add(Dense(n_nodes, input_dim=latent_dim))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Reshape((7, 7, 128)))\n        \n    # upsample to 14x14\n    model.add(Conv2DTranspose(128, (2,2), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n        \n    # usample to 28x28\n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))          \n    model.add(Conv2D(1, (7,7), activation='sigmoid', padding='same'))\n        \n    model.compile(optimizer='Adam', loss='binary_crossentropy')\n                  \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:23:54.420638Z","iopub.execute_input":"2021-07-11T10:23:54.420956Z","iopub.status.idle":"2021-07-11T10:23:54.437488Z","shell.execute_reply.started":"2021-07-11T10:23:54.420918Z","shell.execute_reply":"2021-07-11T10:23:54.436366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def GAN(gen, dis):\n    dis.trainable = False\n    model = Sequential()\n    model.add(gen)\n    model.add(dis)\n        \n    model.compile(optimizer='Adam', loss='binary_crossentropy')\n        \n    return model\n    \ndef latent_point(latent_dim, n_sample):\n    x_input = randn(latent_dim * n_sample)\n    x_input = x_input.reshape(n_sample, latent_dim)\n    return x_input\n    \ndef real_sample(n_sample, data):\n    rand_ind = randint(0, data.shape[0], n_sample)\n    x = data[rand_ind]\n    x = x.reshape(-1,28,28,1)\n    y = ones((n_sample,1))\n        \n    return x, y\n    \ndef fake_sample(gen, n_sample, latent_dim=100):\n    rand_latent_point = latent_point(latent_dim, n_sample)\n    x = gen.predict(rand_latent_point)\n    y = zeros((n_sample, 1))\n        \n    return x, y\n    \ndef evaluate_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n    # prepare real samples\n    X_real, y_real = real_sample(n_samples, dataset)\n    # evaluate discriminator on real examples\n    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n    # prepare fake examples\n    x_fake, y_fake = fake_sample(g_model, n_samples, latent_dim)\n    # evaluate discriminator on fake examples\n    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n    # summarize discriminator performance\n    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n    # save plot\n    save_plot(x_fake, epoch)\n    # save the generator model tile file\n    filename = 'generator_model_%03d.h5' % (epoch + 1)\n    g_model.save(filename)\n        \ndef save_plot(examples, epoch, n=10):\n    # plot images\n    for i in range(n * n):\n        # define subplot\n        pyplot.subplot(n, n, 1 + i)\n        # turn off axis\n        pyplot.axis('off')\n        # plot raw pixel data\n        pyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n    # save plot to file\n    filename = 'generated_plot_e%03d.png' % (epoch+1)\n    pyplot.savefig(filename)\n    pyplot.close()\n    \ndef random_stack(a, b):\n    assert len(a) == len(b)\n    shuffled_a = np.empty(a.shape, dtype=a.dtype)\n    shuffled_b = np.empty(b.shape, dtype=b.dtype)\n    permutation = np.random.permutation(len(a))\n    for old_index, new_index in enumerate(permutation):\n        shuffled_a[new_index] = a[old_index]\n        shuffled_b[new_index] = b[old_index]\n    return shuffled_a, shuffled_b\n       \ndef train(gan, dis, epochs, batch_size, data, latent_dim=100):\n    bat_per_epoch = int(data.shape[0]/batch_size)\n    half_batch = int(batch_size/2)\n        \n    for i in range(epochs):\n        for j in range(bat_per_epoch):\n            real_x, real_y = real_sample(half_batch, data)\n            fake_x, fake_y = fake_sample(gen, half_batch)\n            x, y = vstack((real_x,fake_x)), vstack((real_y,fake_y))\n            x, y = random_stack(x, y)\n            dis_loss,_ = dis.train_on_batch(x, y)\n            \n            gan_x = latent_point(latent_dim, half_batch)\n            gan_y = ones((half_batch, 1))\n            gan_loss = gan.train_on_batch(gan_x, gan_y)\n            if j%15==0:\n                print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epoch, dis_loss, gan_loss))\n                evaluate_performance(epoch=i, g_model=gen, d_model=dis, dataset=data, latent_dim=latent_dim)\n                                        \n        if (i+1) % 10 == 0:\n            evaluate_performance(i, gen, dis, data, latent_dim)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:26:43.012561Z","iopub.execute_input":"2021-07-11T10:26:43.012959Z","iopub.status.idle":"2021-07-11T10:26:43.030664Z","shell.execute_reply.started":"2021-07-11T10:26:43.012921Z","shell.execute_reply":"2021-07-11T10:26:43.029464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/digit-recognizer/train.csv')\n\ndata = data.drop(columns='label')\ndata = data.values\ndata = expand_dims(data, axis=-1)\ndata = data.astype('float32')\ndata = data/255","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:23:54.459584Z","iopub.execute_input":"2021-07-11T10:23:54.460075Z","iopub.status.idle":"2021-07-11T10:23:57.00328Z","shell.execute_reply.started":"2021-07-11T10:23:54.460029Z","shell.execute_reply":"2021-07-11T10:23:57.002361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dis = discriminator()\ngen = generator(100)\ngan = GAN(gen, dis)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:23:57.005007Z","iopub.execute_input":"2021-07-11T10:23:57.005398Z","iopub.status.idle":"2021-07-11T10:23:57.22646Z","shell.execute_reply.started":"2021-07-11T10:23:57.005356Z","shell.execute_reply":"2021-07-11T10:23:57.225433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(gan, dis, 100, 32, data)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:24:19.200795Z","iopub.execute_input":"2021-07-11T10:24:19.201308Z","iopub.status.idle":"2021-07-11T10:25:11.389415Z","shell.execute_reply.started":"2021-07-11T10:24:19.201274Z","shell.execute_reply":"2021-07-11T10:25:11.387719Z"},"trusted":true},"execution_count":null,"outputs":[]}]}